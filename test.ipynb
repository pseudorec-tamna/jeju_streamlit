{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "\n",
    "template_chat = '''당신은 탐라는 맛의 탐나 모델입니다. \n",
    "사용자가 당신에게 누군지 물으면 '맛집을 추천해주는 탐나라고 소개하십시오. \n",
    "긍정적이고 발랄하게 제주도민의 느낌을 살려서 질문의 답변을 도와주세요.\n",
    "참고로 모든 답변은 모두 한국어로 해주세요. \n",
    "\n",
    "당신이 할 수 있는 기능은 아래와 같습니다. \n",
    "- 근처 맛집 추천 : 사용자의 현재 위치 혹은 원하는 장소에서 가장 가까운 맛집을 추천해줍니다.(주소를 최대한 자세하게 알려주세요.) 예) 제주시 애월읍 가문동길 27-8 제주달에서 가장 가까운 맛집을 추천해주세요. \n",
    "- 다음에 갈 장소 추천 : 사용자가 마지막에 들린 장소로부터 다음으로 가장 많이 방문하는 맛집, 카페, 술집, 관광지등을 추천해줍니다.\n",
    "- 속성에 기반한 추천 : 업종, 평균이용금액, 현지인 이용 비중 등을 요청해주시면 이를 고려해서 맛집을 추천해줍니다. \n",
    "'''\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template_chat),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "recommendation_template_chat = '''당신은 탐라는 맛의 탐나 모델입니다. \n",
    "사용자가 당신에게 누군지 물으면 '맛집을 추천해주는 탐나라고 소개하십시오. \n",
    "아래의 주어진 <추천 결과> 및 <거리 정보>를 참고해서 질문의 답변을 도와주세요. \n",
    "참고로 모든 답변은 모두 한국어로 해주세요. \n",
    "\n",
    "<추천 결과> \n",
    "{recommendations}\n",
    "\n",
    "<답변 포맷> \n",
    "🎬 가게명: ㅇㅇㅇ\n",
    "🎥 업종: ㅇㅇㅇ\n",
    "📄 대표 메뉴: ㅇㅇㅇ\n",
    "🕴️ 주소: ㅇㅇㅇ\n",
    "📄 영업시간: ㅇㅇㅇ\n",
    "📄 예약 유무: ㅇㅇㅇ\n",
    "📄 주차 유무: ㅇㅇㅇ\n",
    "📄 추천 이유: ㅇㅇㅇ\n",
    "'''\n",
    "\n",
    "recommendation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", recommendation_template_chat),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "recommendation_sql_template_chat = '''당신은 탐라는 맛의 탐나 모델입니다. \n",
    "사용자가 당신에게 누군지 물으면 '맛집을 추천해주는 탐나라고 소개하십시오. \n",
    "아래의 주어진 <추천 결과> 및 <검색 정보>를 참고해서 질문의 답변을 도와주세요. \n",
    "참고로 모든 답변은 모두 한국어로 해주세요. \n",
    "\n",
    "<검색 정보>\n",
    "{search_info}\n",
    "\n",
    "<추천 결과> \n",
    "{recommendations}\n",
    "\n",
    "답변의 포맷은 아래와 같습니다. \n",
    "🎬 가게명: ㅇㅇㅇ\n",
    "🎥 업종: ㅇㅇㅇ\n",
    "📄 대표 메뉴: ㅇㅇㅇ\n",
    "🕴️ 주소: ㅇㅇㅇ\n",
    "📄 영업시간: ㅇㅇㅇ\n",
    "📄 예약 유무: ㅇㅇㅇ\n",
    "📄 주차 유무: ㅇㅇㅇ\n",
    "📄 추천 이유: ㅇㅇㅇ\n",
    "'''\n",
    "\n",
    "recommendation_sql_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", recommendation_sql_template_chat),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "item_serach_template_chat = '''당신은 탐라는 맛의 탐나 모델입니다. \n",
    "사용자가 당신에게 누군지 물으면 '맛집을 추천해주는 탐나라고 소개하십시오. \n",
    "아래의 주어진 <가게 정보>를 참고해서 질문의 답변을 도와주세요.\n",
    "참고로 모든 답변은 모두 한국어로 해주세요. \n",
    "\n",
    "<가게 정보> \n",
    "- 가게명 : {MCT_NM}\n",
    "- 위치 : {ADDR}\n",
    "- 전화번호 : {tel}\n",
    "- 예약 가능 유무 : {booking}\n",
    "'''\n",
    "\n",
    "item_search_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", item_serach_template_chat),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from utils.chat_state import ChatState\n",
    "from utils.prompts import chat_prompt_template, recommendation_prompt_template, recommendation_sql_prompt_template, item_search_prompt_template\n",
    "\n",
    "from recommendation.prompt import sub_task_detection_prompt\n",
    "from recommendation.utils import json_format\n",
    "# from colorama import Fore, Style\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from recommendation.utils import sub_task_detection\n",
    "from recommendation.distance_based import distance_based_recommendation, get_coordinates_by_question, coordinates_based_recommendation\n",
    "import requests, time\n",
    "import subprocess\n",
    "from recommendation.sql_based import extract_sql_query, sql_based_recommendation\n",
    "from recommendation.prompt import template_sql_prompt\n",
    "# from tamla import load_memory\n",
    "from utils.lang_utils import pairwise_chat_history_to_msg_list\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/additional_info.csv\", encoding='cp949')\n",
    "df = df.drop_duplicates(subset=[\"MCT_NM\"], keep=\"last\")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "database = pd.read_csv(\"./data/JEJU_MCT_DATA_v2.csv\", encoding='cp949')\n",
    "meta_info = database.drop_duplicates(subset=[\"MCT_NM\"], keep=\"last\")\n",
    "df = df.merge(meta_info[[\"MCT_NM\", \"MCT_TYPE\"]], how=\"left\", on=\"MCT_NM\")\n",
    "\n",
    "def load_memory(input, chat_state):\n",
    "    # print(\"chat_state:\", chat_state.memory)\n",
    "    memory_vars = chat_state.memory.load_memory_variables({})\n",
    "    memory_vars[\"chat_history\"] = pairwise_chat_history_to_msg_list(chat_state.chat_history)\n",
    "    # print(\"chat_history:\", memory_vars[\"chat_history\"])\n",
    "    # memory_vars.get(\"chat_history\", [])\n",
    "    return memory_vars.get(\"chat_history\", [])\n",
    "\n",
    "def get_hw_response(chat_state: ChatState):\n",
    "    # Initialize the Gemini 1.5 Flash LLM\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=chat_state.bot_settings.llm_model_name,\n",
    "        google_api_key=chat_state.google_api_key\n",
    "    )\n",
    "\n",
    "    response = sub_task_detection(chat_state.message)\n",
    "    response_type = json_format(response)[\"response_type\"]\n",
    "\n",
    "    if response_type == \"Chat\":\n",
    "        chain = RunnablePassthrough.assign(chat_history=lambda input: load_memory(input, chat_state)) | chat_prompt_template | llm\n",
    "        result = chain.invoke({\"question\": chat_state.message})\n",
    "\n",
    "    elif response_type == \"Recommendation\":\n",
    "        \n",
    "        if json_format(response)[\"recommendation_type\"] == \"Distance-based\":\n",
    "            chain = RunnablePassthrough.assign(chat_history=lambda input: load_memory(input, chat_state)) | recommendation_prompt_template | llm\n",
    "            coord = get_coordinates_by_question(chat_state.message)\n",
    "            print(\"정확한 주소를 지도에서 검색후에 클릭해주세요 !!\")\n",
    "\n",
    "            from IPython.display import IFrame\n",
    "            latitude, longitude = coord  # coord에서 위도와 경도 추출\n",
    "            display(IFrame(src='http://127.0.0.1:5000', width=1200, height=600))\n",
    "            \n",
    "            while True: \n",
    "                response = requests.get('http://127.0.0.1:5000/get_coordinates')\n",
    "                coordinates = response.json()\n",
    "                latitude = coordinates['latitude']\n",
    "                longitude = coordinates['longitude']\n",
    "                if latitude is not None and longitude is not None:\n",
    "                    break\n",
    "                time.sleep(5)\n",
    "            \n",
    "            rec = coordinates_based_recommendation((longitude, latitude), df)\n",
    "            result = chain.invoke({\"question\": chat_state.message, \"recommendations\": rec})  \n",
    "        elif json_format(response)[\"recommendation_type\"] == \"Attribute-based\":\n",
    "            chain = RunnablePassthrough.assign(chat_history=lambda input: load_memory(input, chat_state)) | recommendation_sql_prompt_template | llm\n",
    "            sql_prompt = ChatPromptTemplate.from_template(template_sql_prompt)\n",
    "            sql_chain = sql_prompt | llm\n",
    "            output = sql_chain.invoke({\"question\": chat_state.message})            \n",
    "            rec = sql_based_recommendation(output, df)\n",
    "            result = chain.invoke({\"question\": chat_state.message, \"recommendations\": rec, \"search_info\": output.content})  \n",
    "        else: \n",
    "            pass \n",
    "              \n",
    "    elif response_type == \"Item Detail Search\":\n",
    "        # SQL 문으로 검색 가능하도록 \n",
    "\n",
    "        chain = RunnablePassthrough.assign(chat_history=lambda input: load_memory(input, chat_state)) | item_search_prompt_template | llm\n",
    "        item_info = df.loc[df[\"MCT_NM\"] == str(chat_state.message)].reset_index(drop=True)\n",
    "        print(\"item_info:\", item_info)\n",
    "        result = chain.invoke({\n",
    "            \"question\": chat_state.message,\n",
    "            \"MCT_NM\": item_info[\"MCT_NM\"],\n",
    "            \"ADDR\": item_info[\"ADDR\"],\n",
    "            \"tel\": item_info[\"tel\"],\n",
    "            \"booking\": item_info[\"booking\"]\n",
    "            })\n",
    "    else: \n",
    "        pass \n",
    "    response = {\"answer\": result.content}\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyungah/Jupyter/Pseudo/Jeju_chatbot-main/utils/type_utils.py:145: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
      "/Users/gyungah/Jupyter/Pseudo/Jeju_chatbot-main/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from agents.greeting_quick import jeju_weather_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jeju_weather_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
